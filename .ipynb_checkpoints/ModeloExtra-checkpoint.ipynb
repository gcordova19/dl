{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmdQKr4JZG0_",
    "outputId": "19031b8e-9d20-48c0-f569-90d5c913ebe4"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wGROfSEVZVf9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import pandas\n",
    "#import imageio.v3 as io\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from typing import Optional, Union\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mQhbsdGvZZLV"
   },
   "outputs": [],
   "source": [
    "# Comprobamos a abrirlos de nuevo /content/drive/MyDrive/datos/filtered_data_Test.csv\n",
    "saved_data_Train = pandas.read_csv(\"filtered_data_Train.csv\", sep=';')\n",
    "saved_imgs_Train = numpy.load(\"imageTrain.npy\")\n",
    "saved_data_Train.shape, saved_imgs_Train.shape\n",
    "\n",
    "y_train = saved_data_Train.iloc[:, 0:1]   # Seleccionamos la primera columna, price\n",
    "X_train = saved_data_Train.iloc[:, 1:-1]  # Seleccionamos todas las columnas excepto la primera y la última\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)\n",
    "\n",
    "X_train = XtrainScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HKrIkbukZejt"
   },
   "outputs": [],
   "source": [
    "# Comprobamos a abrirlos de nuevo\n",
    "saved_data_Test = pandas.read_csv(\"filtered_data_Test.csv\", sep=';')\n",
    "saved_imgs_Test = numpy.load(\"imagesTest.npy\")\n",
    "saved_data_Test.shape, saved_imgs_Test.shape\n",
    "\n",
    "y_test = saved_data_Test.iloc[:, 0:1]      # nos quedamos con la 1ª columna, price\n",
    "X_test = saved_data_Test.iloc[:,1:-1]      # nos quedamos con el resto\n",
    "\n",
    "\n",
    "# recordad que esta normalización/escalado la realizo con el scaler anterior, basado en los datos de training!\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "X_test = XtestScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kKVPrNCXZm89"
   },
   "outputs": [],
   "source": [
    "# Comprobamos a abrirlos de nuevo\n",
    "saved_data_Val = pandas.read_csv(\"filtered_data_Val.csv\", sep=';')\n",
    "saved_imgs_Val = numpy.load(\"imagesVal.npy\")\n",
    "saved_data_Val.shape, saved_imgs_Val.shape\n",
    "\n",
    "y_val = saved_data_Val.iloc[:,0:1]     # nos quedamos con la 1ª columna, price\n",
    "X_val = saved_data_Val.iloc[:,1:-1]      # nos quedamos con el resto\n",
    "\n",
    "\n",
    "# recordad que esta normalización/escalado la realizo con el scaler anterior, basado en los datos de training!\n",
    "XvalScaled = scaler.transform(X_val)\n",
    "\n",
    "X_val = XvalScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FI10v8CJnn2S"
   },
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "X_train_img = saved_imgs_Train\n",
    "X_test_img = saved_imgs_Test\n",
    "X_val_img = saved_imgs_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pJRqXNYrXwB",
    "outputId": "3c626733-a040-402d-f1f7-d5f2bd2b296e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6762, 224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vbFvPtZ5cHU"
   },
   "source": [
    "Siguiendo el tutorial parahacer Early fusion pero con cambios como el modelo cnn https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rZTAV6MFo-vo"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0KmnRbaDo_3G"
   },
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False):\n",
    "\t# define our MLP network\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "\tmodel.add(Dense(4, activation=\"relu\"))\n",
    "\t# check to see if the regression node should be added\n",
    "\tif regress:\n",
    "\t\tmodel.add(Dense(1, activation=\"linear\"))\n",
    "\t# return our model\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BaxfyAN8qaXN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "def create_cnn(width, height, depth, regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "\n",
    "    # construct the top of the model that will be placed on top of the base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # check if it's a regression task\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the final model\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # return the model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "P8XmC3yzZhnn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# create the MLP and CNN models\n",
    "mlp = create_mlp(X_train.shape[1], regress=False)\n",
    "cnn = create_cnn(224, 224, 3, regress=False)\n",
    "\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "learning_rate = 0.001\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8rhDa3MFILn"
   },
   "source": [
    "La idea principal es tomar los datos de las imagenes y pasarlo por una CNN y usar los datos tabulares en una MLP. La diferencia en en modelo CNN es que se usa un modelo preentrenado VGG16 con el fin de obtener mejores resultado que usar una desde cero. antes de aplicar la regresion conctenamos las salidas y agregamos dos capas densas para obtener la regresion del precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aldS2LwIuYls",
    "outputId": "8961cdbe-40ab-481c-9ef0-4cc3434958a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5_input (InputLayer)     [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 8)            104         ['dense_5_input[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          3211392     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            36          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 132)          0           ['dense_6[0][0]',                \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 4)            532         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            5           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,926,757\n",
      "Trainable params: 17,926,757\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Crear el callback ModelCheckpoint\u001b[39;00m\n\u001b[1;32m     10\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(checkpoint_filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_img\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "#Mostrar las capas\n",
    "model.summary()\n",
    "\n",
    "# Definir el nombre del archivo para guardar el mejor modelo\n",
    "checkpoint_filepath = '/tf/data/mejor_modelo_mix.h5'\n",
    "# Crear el callback ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "\tx=[X_train, X_train_img], y=y_train,\n",
    "\tvalidation_data=([X_val, X_val_img], y_val),\n",
    "\tepochs=2, batch_size=16, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0AoEr0zwBa4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Cargar el mejor modelo guardado\n",
    "best_model = tf.keras.models.load_model('mejor_modelo_mix.h5')\n",
    "# Obtener el historial de entrenamiento del mejor modelo\n",
    "best_model_history = history.history\n",
    "\n",
    "# Obtener las métricas de entrenamiento y validación del mejor modelo\n",
    "train_loss = best_model_history['loss']\n",
    "val_loss = best_model_history['val_loss']\n",
    "#train_mse = best_model_history['mse']\n",
    "#val_mse = best_model_history['val_mse']\n",
    "\n",
    "# Mostrar gráfica de loss y métrica de entrenamiento y validación\n",
    "plt.style.use(\"ggplot\")\n",
    "num_epochs =10\n",
    "# Gráfico de pérdida\n",
    "plt.figure()\n",
    "epochs = range(1, num_epochs + 1)\n",
    "plt.plot(epochs, train_loss, label=\"train_loss\")\n",
    "plt.plot(epochs, val_loss, label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting house prices...\")\n",
    "preds = best_model.predict([X_test, X_test_img])\n",
    "diff = preds.flatten() - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD_4Hx1LGCtg"
   },
   "source": [
    "En este caso la estrategia ha sido seguir los pasos de un tutorial que explicaba lo que era. Aunque ha sido confuso se ejecuto pero los multiples problemas de colab en el uso gratuito no conseguia termina. Se agregaron recursos de almacenage el modelo mejor pero no tubo tiempo de terminar. Ademas se configuro un PC en local para ejecutar pero tenia el error que se ve en el jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
